apiVersion: argoproj.io/v1alpha1
kind: Workflow
metadata:
  generateName: dkube-mnist-pl-
  annotations: {pipelines.kubeflow.org/kfp_sdk_version: 1.0.0, pipelines.kubeflow.org/pipeline_compilation_time: '2020-08-28T13:25:35.818805',
    pipelines.kubeflow.org/pipeline_spec: '{"description": "sample mnist digits pipeline
      with dkube components", "inputs": [{"name": "auth_token"}, {"name": "training_program"},
      {"name": "training_dataset"}, {"name": "training_output_model"}, {"default":
      "default", "name": "job_group", "optional": true}, {"default": "tensorflow",
      "name": "framework", "optional": true}, {"default": "1.14", "name": "version",
      "optional": true}, {"default": "{\"image\": \"docker.io/ocdr/d3-datascience-tf-cpu:v1.14\",
      \"username\": \"\", \"password\": \"\"}", "name": "training_container", "optional":
      true}, {"default": "python model.py", "name": "training_script", "optional":
      true}, {"default": "{}", "name": "tuning", "optional": true}, {"default": "/opt/dkube/input",
      "name": "training_input_dataset_mount", "optional": true}, {"default": "/opt/dkube/output",
      "name": "training_output_mount", "optional": true}, {"default": "0", "name":
      "training_gpus", "optional": true}, {"default": "[{\"steps\": 100}]", "name":
      "training_envs", "optional": true}, {"default": "cpu", "name": "serving_device",
      "optional": true}, {"default": "{\"image\": \"ocdr/tensorflowserver:1.14\",
      \"username\": \"\", \"password\": \"\"}", "name": "serving_image", "optional":
      true}, {"default": "{\"image\": \"docker.io/ocdr/mnist-example-preprocess:2.0.7\",
      \"username\": \"\", \"password\": \"\"}", "name": "transformer_image", "optional":
      true}, {"default": "tensorflow/classification/mnist/digits/transformer/transformer.py",
      "name": "transformer_code", "optional": true}], "name": "dkube-mnist-pl"}'}
  labels: {pipelines.kubeflow.org/kfp_sdk_version: 1.0.0}
spec:
  entrypoint: dkube-mnist-pl
  templates:
  - name: dkube-mnist-pl
    inputs:
      parameters:
      - {name: auth_token}
      - {name: framework}
      - {name: job_group}
      - {name: serving_device}
      - {name: serving_image}
      - {name: training_container}
      - {name: training_dataset}
      - {name: training_envs}
      - {name: training_gpus}
      - {name: training_input_dataset_mount}
      - {name: training_output_model}
      - {name: training_output_mount}
      - {name: training_program}
      - {name: training_script}
      - {name: transformer_code}
      - {name: transformer_image}
      - {name: tuning}
      - {name: version}
    dag:
      tasks:
      - name: dkube-serving
        template: dkube-serving
        dependencies: [dkube-training]
        arguments:
          parameters:
          - {name: auth_token, value: '{{inputs.parameters.auth_token}}'}
          - {name: dkube-training-artifact, value: '{{tasks.dkube-training.outputs.parameters.dkube-training-artifact}}'}
          - {name: serving_device, value: '{{inputs.parameters.serving_device}}'}
          - {name: serving_image, value: '{{inputs.parameters.serving_image}}'}
          - {name: training_program, value: '{{inputs.parameters.training_program}}'}
          - {name: transformer_code, value: '{{inputs.parameters.transformer_code}}'}
          - {name: transformer_image, value: '{{inputs.parameters.transformer_image}}'}
      - name: dkube-training
        template: dkube-training
        arguments:
          parameters:
          - {name: auth_token, value: '{{inputs.parameters.auth_token}}'}
          - {name: framework, value: '{{inputs.parameters.framework}}'}
          - {name: job_group, value: '{{inputs.parameters.job_group}}'}
          - {name: training_container, value: '{{inputs.parameters.training_container}}'}
          - {name: training_dataset, value: '{{inputs.parameters.training_dataset}}'}
          - {name: training_envs, value: '{{inputs.parameters.training_envs}}'}
          - {name: training_gpus, value: '{{inputs.parameters.training_gpus}}'}
          - {name: training_input_dataset_mount, value: '{{inputs.parameters.training_input_dataset_mount}}'}
          - {name: training_output_model, value: '{{inputs.parameters.training_output_model}}'}
          - {name: training_output_mount, value: '{{inputs.parameters.training_output_mount}}'}
          - {name: training_program, value: '{{inputs.parameters.training_program}}'}
          - {name: training_script, value: '{{inputs.parameters.training_script}}'}
          - {name: tuning, value: '{{inputs.parameters.tuning}}'}
          - {name: version, value: '{{inputs.parameters.version}}'}
  - name: dkube-serving
    container:
      args: [serving, --accessurl, --token, '{{inputs.parameters.auth_token}}', --model,
        '{{inputs.parameters.dkube-training-artifact}}', --device, '{{inputs.parameters.serving_device}}',
        --serving_image, '{{inputs.parameters.serving_image}}', --transformer_image,
        '{{inputs.parameters.transformer_image}}', --transformer_project, '{{inputs.parameters.training_program}}',
        --transformer_code, '{{inputs.parameters.transformer_code}}', --transformer_commit_id,
        --runid, '{{pod.name}}', --wfid, '{{workflow.uid}}']
      command: [dkubepl]
      image: ocdr/dkubepl:2.1.3.1
    inputs:
      parameters:
      - {name: auth_token}
      - {name: dkube-training-artifact}
      - {name: serving_device}
      - {name: serving_image}
      - {name: training_program}
      - {name: transformer_code}
      - {name: transformer_image}
    outputs:
      artifacts:
      - {name: dkube-serving-rundetails, path: /tmp/rundetails}
      - {name: dkube-serving-servingurl, path: /tmp/servingurl}
    metadata:
      annotations: {platform: Dkube, pipelines.kubeflow.org/component_spec: '{"description":
          "Component which can be used to deploy a trained model on Dkube platform.\nDkube
          serving provides,\n* Option to deploy with CPU/GPU.\n* A web server in the
          front and all the required infra to access the server.\n* Deployed as microserice.
          Serving URL is provided for any other application logic to consume the model.\n*
          Attempts to decode and present some abstract information about the model.\n",
          "implementation": {"container": {"args": ["serving", "--accessurl", {"inputValue":
          "access_url"}, "--token", {"inputValue": "auth_token"}, "--model", {"inputValue":
          "model"}, "--device", {"inputValue": "device"}, "--serving_image", {"inputValue":
          "serving_image"}, "--transformer_image", {"inputValue": "transformer_image"},
          "--transformer_project", {"inputValue": "transformer_project"}, "--transformer_code",
          {"inputValue": "transformer_code"}, "--transformer_commit_id", {"inputValue":
          "transformer_commit_id"}, "--runid", "{{pod.name}}", "--wfid", "{{workflow.uid}}"],
          "command": ["dkubepl"], "fileOutputs": {"rundetails": "/tmp/rundetails",
          "servingurl": "/tmp/servingurl"}, "image": "ocdr/dkubepl:2.1.3.1"}}, "inputs":
          [{"description": "Required. Dkube authentication token.", "name": "auth_token",
          "type": "String"}, {"description": "Required. Trained model in Dkube which
          is to be deployed for serving.", "name": "model", "type": "String"}, {"default":
          "cpu", "description": "Optional. Device to use for serving - allowed values,
          gpu/cpu/auto.", "name": "device", "optional": true, "type": "String"}, {"default":
          "", "description": "Optional. URL at which dkube is accessible, copy paste
          from the browser of this window. Required for cloud deployments.", "name":
          "access_url", "optional": true, "type": "String"}, {"description": "Required.
          Container to use for serving. Format: {\"image\":<url>, \"username\":<>,
          \"password\":<>}", "name": "serving_image", "type": "Dict"}, {"description":
          "Required. Container to use as transformer. Format: {\"image\":<url>, \"username\":<>,
          \"password\":<>}", "name": "transformer_image", "type": "Dict"}, {"description":
          "Required. Transformer project.", "name": "transformer_project", "type":
          "String"}, {"description": "Required. Transformer script.", "name": "transformer_code",
          "type": "String"}, {"description": "Optional. Transformer project commit
          ID.", "name": "transformer_commit_id", "optional": true, "type": "String"}],
          "metadata": {"annotations": {"platform": "Dkube"}, "labels": {"dkube.garbagecollect":
          "true", "dkube.garbagecollect.policy": "all", "logger": "dkubepl", "platform":
          "Dkube", "runid": "{{pod.name}}", "stage": "serving", "wfid": "{{workflow.uid}}"}},
          "name": "dkube-serving", "outputs": [{"description": "Details of the dkube
          run", "name": "rundetails"}, {"description": "URL at which the serving web
          server is accessible.", "name": "servingurl"}]}', pipelines.kubeflow.org/component_ref: '{"digest":
          "e61a693340c7bfd28eac9688d43825da967caec12fdb3429f0a6fcd37fb2fc33", "url":
          "../components/serving/component.yaml"}'}
      labels:
        platform: Dkube
        logger: dkubepl
        wfid: '{{workflow.uid}}'
        runid: '{{pod.name}}'
        stage: serving
        dkube.garbagecollect: "true"
        dkube.garbagecollect.policy: all
  - name: dkube-training
    container:
      args: [training, --accessurl, --token, '{{inputs.parameters.auth_token}}', --container,
        '{{inputs.parameters.training_container}}', --script, '{{inputs.parameters.training_script}}',
        --program, '{{inputs.parameters.training_program}}', --datasets, '["{{inputs.parameters.training_dataset}}"]',
        --input_dataset_mounts, '["{{inputs.parameters.training_input_dataset_mount}}"]',
        --models, --input_model_mounts, --outputs, '["{{inputs.parameters.training_output_model}}"]',
        --output_mounts, '["{{inputs.parameters.training_output_mount}}"]', --ngpus,
        '{{inputs.parameters.training_gpus}}', --nworkers, --auto, --config, --tuning,
        '{{inputs.parameters.tuning}}', --envs, '{{inputs.parameters.training_envs}}',
        --gdrdma, --job_group, '{{inputs.parameters.job_group}}', --framework, '{{inputs.parameters.framework}}',
        --version, '{{inputs.parameters.version}}', --runid, '{{pod.name}}', --wfid,
        '{{workflow.uid}}']
      command: [dkubepl]
      image: ocdr/dkubepl:2.1.3.1
    inputs:
      parameters:
      - {name: auth_token}
      - {name: framework}
      - {name: job_group}
      - {name: training_container}
      - {name: training_dataset}
      - {name: training_envs}
      - {name: training_gpus}
      - {name: training_input_dataset_mount}
      - {name: training_output_model}
      - {name: training_output_mount}
      - {name: training_program}
      - {name: training_script}
      - {name: tuning}
      - {name: version}
    outputs:
      parameters:
      - name: dkube-training-artifact
        valueFrom: {path: /tmp/artifact}
      artifacts:
      - {name: dkube-training-artifact, path: /tmp/artifact}
      - {name: dkube-training-rundetails, path: /tmp/rundetails}
    metadata:
      annotations: {platform: Dkube, pipelines.kubeflow.org/component_spec: '{"description":
          "Component which can be used to do training for deep learning models on
          Dkube platform.\nDkube training offers,\n* Advanced options for distributed
          training, gpu managment & pooling.\n* Support Hyper parameter tuning.\n*
          GDRDMA support for Horovod like training programs.\n* Ability to orchestrate
          and run custom training containers, prebuilt dkube datascience containers
          can also be used.\n* Renders nice Dashboard for training metrics and utilization
          graphs for GPU, CPU, Memory.\n* Support for early stopping if program is
          not converging - User can abort the Job and resume from previous point in
          training.\n* Tags to group related training jobs.\n", "implementation":
          {"container": {"args": ["training", "--accessurl", {"inputValue": "access_url"},
          "--token", {"inputValue": "auth_token"}, "--container", {"inputValue": "container"},
          "--script", {"inputValue": "run_script"}, "--program", {"inputValue": "program"},
          "--datasets", {"inputValue": "datasets"}, "--input_dataset_mounts", {"inputValue":
          "input_dataset_mounts"}, "--models", {"inputValue": "models"}, "--input_model_mounts",
          {"inputValue": "input_model_mounts"}, "--outputs", {"inputValue": "outputs"},
          "--output_mounts", {"inputValue": "output_mounts"}, "--ngpus", {"inputValue":
          "ngpus"}, "--nworkers", {"inputValue": "nworkers"}, "--auto", {"inputValue":
          "auto_distribute"}, "--config", {"inputValue": "config"}, "--tuning", {"inputValue":
          "tuning"}, "--envs", {"inputValue": "envs"}, "--gdrdma", {"inputValue":
          "gdrdma"}, "--job_group", {"inputValue": "job_group"}, "--framework", {"inputValue":
          "framework"}, "--version", {"inputValue": "version"}, "--runid", "{{pod.name}}",
          "--wfid", "{{workflow.uid}}"], "command": ["dkubepl"], "fileOutputs": {"artifact":
          "/tmp/artifact", "rundetails": "/tmp/rundetails"}, "image": "ocdr/dkubepl:2.1.3.1"}},
          "inputs": [{"description": "Required. Dkube authentication token.", "name":
          "auth_token", "type": "String"}, {"description": "Required. Container to
          use for training. Format: {\"image\":<url>, \"username\":<>, \"password\":<>}",
          "name": "container", "type": "Dict"}, {"default": "", "description": "Optional.
          Program imported in Dkube to be run inside container. If not specified container
          should have entrypoint.", "name": "program", "optional": true, "type": "String"},
          {"default": "", "description": "Optional. Script to run the program. If
          not specified container should have entrypoint.", "name": "run_script",
          "optional": true, "type": "String"}, {"default": "[]", "description": "Optional.
          List of input datasets required for training. These datasets must be created
          in Dkube.", "name": "datasets", "optional": true, "type": "List"}, {"default":
          "[]", "description": "Optional. List of input datasets mount paths.", "name":
          "input_dataset_mounts", "optional": true, "type": "List"}, {"default": "[]",
          "description": "Optional. List of input models required for training. These
          models must be created in Dkube.", "name": "models", "optional": true, "type":
          "List"}, {"default": "[]", "description": "Optional. List of input models
          mount paths.", "name": "input_model_mounts", "optional": true, "type": "List"},
          {"default": "[]", "description": "Required. List of output models of a training",
          "name": "outputs", "optional": true, "type": "List"}, {"default": "[]",
          "description": "Required. List of output model mount paths", "name": "output_mounts",
          "optional": true, "type": "List"}, {"default": 0, "description": "Optional.
          Number of gpus the training program should use.", "name": "ngpus", "optional":
          true, "type": "Integer"}, {"default": 0, "description": "Optional. Number
          of workers for training, >0 for distributed training.", "name": "nworkers",
          "optional": true, "type": "Integer"}, {"default": "false", "description":
          "Optional. Should Dkube auto distribute based on available number of resources.",
          "name": "auto_distribute", "optional": true, "type": "String"}, {"default":
          "", "description": "Optional. HP file or configuration data required for
          training program. Supported inputs - d3s://<path> - Path to a file in dkube
          storage. <string> - Inline data", "name": "config", "optional": true, "type":
          "String"}, {"default": "", "description": "Optional. HP tuning information.
          Can be a URL to a file with hptuning definition or inline data. Supported
          inputs - d3s://<path> - Path to a file in dkube storage. <string> - Inline
          data, only json formatted string is valid.", "name": "tuning", "optional":
          true, "type": "String"}, {"default": "[]", "description": "Optional. Environments
          for training program. Exact key value will be made available for the container",
          "name": "envs", "optional": true, "type": "List"}, {"default": "false",
          "description": "Optional. Whether to use GDRDMA for distributed training.",
          "name": "gdrdma", "optional": true, "type": "String"}, {"default": "", "description":
          "Optional. URL at which dkube is accessible, copy paste from the browser
          of this window. Required for cloud deployments.", "name": "access_url",
          "optional": true, "type": "String"}, {"default": "default", "description":
          "Optional. Runs can be organized into Groups that allow them to be viewed
          together. This group must be created in Dkube.", "name": "job_group", "optional":
          true, "type": "String"}, {"description": "Required. Framework {tensorflow,
          pytorch, sklearn}.", "name": "framework", "type": "String"}, {"description":
          "Required. Framework version.", "name": "version", "type": "String"}], "metadata":
          {"annotations": {"platform": "Dkube"}, "labels": {"dkube.garbagecollect":
          "true", "dkube.garbagecollect.policy": "all", "logger": "dkubepl", "platform":
          "Dkube", "runid": "{{pod.name}}", "stage": "training", "wfid": "{{workflow.uid}}"}},
          "name": "dkube-training", "outputs": [{"description": "Details of the dkube
          run", "name": "rundetails"}, {"description": "Identifier in Dkube storage
          where artifacts of training are stored.", "name": "artifact"}]}', pipelines.kubeflow.org/component_ref: '{"digest":
          "950b3681631e5c670add34f4dc5ec1e608abf30fe6a4880dc424908fdcda2d73", "url":
          "../components/training/component.yaml"}'}
      labels:
        platform: Dkube
        logger: dkubepl
        wfid: '{{workflow.uid}}'
        runid: '{{pod.name}}'
        stage: training
        dkube.garbagecollect: "true"
        dkube.garbagecollect.policy: all
  arguments:
    parameters:
    - {name: auth_token}
    - {name: training_program}
    - {name: training_dataset}
    - {name: training_output_model}
    - {name: job_group, value: default}
    - {name: framework, value: tensorflow}
    - {name: version, value: '1.14'}
    - {name: training_container, value: '{"image": "docker.io/ocdr/d3-datascience-tf-cpu:v1.14",
        "username": "", "password": ""}'}
    - {name: training_script, value: python model.py}
    - {name: tuning, value: '{}'}
    - {name: training_input_dataset_mount, value: /opt/dkube/input}
    - {name: training_output_mount, value: /opt/dkube/output}
    - {name: training_gpus, value: '0'}
    - {name: training_envs, value: '[{"steps": 100}]'}
    - {name: serving_device, value: cpu}
    - {name: serving_image, value: '{"image": "ocdr/tensorflowserver:1.14", "username":
        "", "password": ""}'}
    - {name: transformer_image, value: '{"image": "docker.io/ocdr/mnist-example-preprocess:2.0.7",
        "username": "", "password": ""}'}
    - {name: transformer_code, value: tensorflow/classification/mnist/digits/transformer/transformer.py}
  serviceAccountName: pipeline-runner
