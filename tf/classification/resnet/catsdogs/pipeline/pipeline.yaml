apiVersion: argoproj.io/v1alpha1
kind: Workflow
metadata:
  generateName: dkube-cats-dogs-pl-
  annotations: {pipelines.kubeflow.org/kfp_sdk_version: 1.0.0, pipelines.kubeflow.org/pipeline_compilation_time: '2020-10-20T07:58:35.652122',
    pipelines.kubeflow.org/pipeline_spec: '{"description": "sample cats dogs pipeline
      with dkube components", "inputs": [{"name": "auth_token"}, {"name": "training_program"},
      {"name": "training_dataset"}, {"name": "training_output_model"}, {"default":
      "default", "name": "job_group", "optional": true}, {"default": "tensorflow",
      "name": "framework", "optional": true}, {"default": "1.14", "name": "version",
      "optional": true}, {"default": "{\"image\": \"docker.io/ocdr/d3-datascience-tf-cpu:v1.14\",
      \"username\": \"\", \"password\": \"\"}", "name": "training_container", "optional":
      true}, {"default": "python model.py", "name": "training_script", "optional":
      true}, {"default": "/opt/dkube/input", "name": "training_input_dataset_mount",
      "optional": true}, {"default": "/opt/dkube/output", "name": "training_output_mount",
      "optional": true}, {"default": "0", "name": "training_gpus", "optional": true},
      {"default": "[{\"steps\": 100}]", "name": "training_envs", "optional": true},
      {"default": "{\"image\": \"ocdr/tensorflowserver:1.14\", \"username\": \"\",
      \"password\": \"\"}", "name": "serving_image", "optional": true}, {"default":
      "{\"image\": \"docker.io/ocdr/d3-datascience-tf-cpu:v1.14\", \"username\": \"\",
      \"password\": \"\"}", "name": "transformer_image", "optional": true}, {"default":
      "tensorflow/classification/resnet/catsdogs/transformer/transformer.py", "name":
      "transformer_code", "optional": true}], "name": "dkube-cats dogs-pl"}'}
  labels: {pipelines.kubeflow.org/kfp_sdk_version: 1.0.0}
spec:
  entrypoint: dkube-cats-dogs-pl
  templates:
  - name: dkube-cats-dogs-pl
    inputs:
      parameters:
      - {name: auth_token}
      - {name: framework}
      - {name: job_group}
      - {name: serving_image}
      - {name: training_container}
      - {name: training_dataset}
      - {name: training_envs}
      - {name: training_gpus}
      - {name: training_input_dataset_mount}
      - {name: training_output_model}
      - {name: training_output_mount}
      - {name: training_program}
      - {name: training_script}
      - {name: transformer_code}
      - {name: transformer_image}
      - {name: version}
    dag:
      tasks:
      - name: dkube-serving
        template: dkube-serving
        dependencies: [dkube-training]
        arguments:
          parameters:
          - {name: auth_token, value: '{{inputs.parameters.auth_token}}'}
          - {name: dkube-training-artifact, value: '{{tasks.dkube-training.outputs.parameters.dkube-training-artifact}}'}
          - {name: serving_image, value: '{{inputs.parameters.serving_image}}'}
          - {name: training_program, value: '{{inputs.parameters.training_program}}'}
          - {name: transformer_code, value: '{{inputs.parameters.transformer_code}}'}
          - {name: transformer_image, value: '{{inputs.parameters.transformer_image}}'}
      - name: dkube-training
        template: dkube-training
        arguments:
          parameters:
          - {name: auth_token, value: '{{inputs.parameters.auth_token}}'}
          - {name: framework, value: '{{inputs.parameters.framework}}'}
          - {name: job_group, value: '{{inputs.parameters.job_group}}'}
          - {name: training_container, value: '{{inputs.parameters.training_container}}'}
          - {name: training_dataset, value: '{{inputs.parameters.training_dataset}}'}
          - {name: training_envs, value: '{{inputs.parameters.training_envs}}'}
          - {name: training_gpus, value: '{{inputs.parameters.training_gpus}}'}
          - {name: training_input_dataset_mount, value: '{{inputs.parameters.training_input_dataset_mount}}'}
          - {name: training_output_model, value: '{{inputs.parameters.training_output_model}}'}
          - {name: training_output_mount, value: '{{inputs.parameters.training_output_mount}}'}
          - {name: training_program, value: '{{inputs.parameters.training_program}}'}
          - {name: training_script, value: '{{inputs.parameters.training_script}}'}
          - {name: version, value: '{{inputs.parameters.version}}'}
  - name: dkube-serving
    container:
      args: [serving, --accessurl, --token, '{{inputs.parameters.auth_token}}', --model,
        '{{inputs.parameters.dkube-training-artifact}}', --model_version, --device,
        --serving_image, '{{inputs.parameters.serving_image}}', --transformer_image,
        '{{inputs.parameters.transformer_image}}', --transformer_project, '{{inputs.parameters.training_program}}',
        --transformer_code, '{{inputs.parameters.transformer_code}}', --transformer_commit_id,
        --runid, '{{pod.name}}', --wfid, '{{workflow.uid}}']
      command: [dkubepl]
      image: ocdr/dkubepl:2.1.6.2
    inputs:
      parameters:
      - {name: auth_token}
      - {name: dkube-training-artifact}
      - {name: serving_image}
      - {name: training_program}
      - {name: transformer_code}
      - {name: transformer_image}
    outputs:
      artifacts:
      - {name: dkube-serving-rundetails, path: /tmp/rundetails}
      - {name: dkube-serving-servingurl, path: /tmp/servingurl}
    metadata:
      annotations: {platform: Dkube, pipelines.kubeflow.org/component_spec: '{"description":
          "Component which can be used to deploy a trained model on Dkube platform.\nDkube
          serving provides,\n* Option to deploy with CPU/GPU.\n* A web server in the
          front and all the required infra to access the server.\n* Deployed as microserice.
          Serving URL is provided for any other application logic to consume the model.\n*
          Attempts to decode and present some abstract information about the model.\n",
          "implementation": {"container": {"args": ["serving", "--accessurl", {"inputValue":
          "access_url"}, "--token", {"inputValue": "auth_token"}, "--model", {"inputValue":
          "model"}, "--model_version", {"inputValue": "model_version"}, "--device",
          {"inputValue": "device"}, "--serving_image", {"inputValue": "serving_image"},
          "--transformer_image", {"inputValue": "transformer_image"}, "--transformer_project",
          {"inputValue": "transformer_project"}, "--transformer_code", {"inputValue":
          "transformer_code"}, "--transformer_commit_id", {"inputValue": "transformer_commit_id"},
          "--runid", "{{pod.name}}", "--wfid", "{{workflow.uid}}"], "command": ["dkubepl"],
          "fileOutputs": {"rundetails": "/tmp/rundetails", "servingurl": "/tmp/servingurl"},
          "image": "ocdr/dkubepl:2.1.6.2"}}, "inputs": [{"description": "Required.
          Dkube authentication token.", "name": "auth_token", "type": "String"}, {"description":
          "Required. Trained model in Dkube which is to be deployed for serving.",
          "name": "model", "type": "String"}, {"description": "Optional. Trained model
          version.", "name": "model_version", "optional": true, "type": "String"},
          {"default": "cpu", "description": "Optional. Device to use for serving -
          allowed values, gpu/cpu/auto.", "name": "device", "optional": true, "type":
          "String"}, {"default": "", "description": "Optional. URL at which dkube
          is accessible, copy paste from the browser of this window. Required for
          cloud deployments.", "name": "access_url", "optional": true, "type": "String"},
          {"description": "Required. Container to use for serving. Format: {\"image\":<url>,
          \"username\":<>, \"password\":<>}", "name": "serving_image", "type": "Dict"},
          {"description": "Required. Container to use as transformer. Format: {\"image\":<url>,
          \"username\":<>, \"password\":<>}", "name": "transformer_image", "type":
          "Dict"}, {"description": "Required. Transformer project.", "name": "transformer_project",
          "type": "String"}, {"description": "Required. Transformer script.", "name":
          "transformer_code", "type": "String"}, {"description": "Optional. Transformer
          project commit ID.", "name": "transformer_commit_id", "optional": true,
          "type": "String"}], "metadata": {"annotations": {"platform": "Dkube"}, "labels":
          {"dkube.garbagecollect": "true", "dkube.garbagecollect.policy": "all", "logger":
          "dkubepl", "platform": "Dkube", "runid": "{{pod.name}}", "stage": "serving",
          "wfid": "{{workflow.uid}}"}}, "name": "dkube-serving", "outputs": [{"description":
          "Details of the dkube run", "name": "rundetails"}, {"description": "URL
          at which the serving web server is accessible.", "name": "servingurl"}]}',
        pipelines.kubeflow.org/component_ref: '{"digest": "671cfb6f74068a71f525dc0ec4482c3f41db6f023f88d920c7f8353ecb7f0cd4",
          "url": "../components/serving/component.yaml"}'}
      labels:
        platform: Dkube
        logger: dkubepl
        wfid: '{{workflow.uid}}'
        runid: '{{pod.name}}'
        stage: serving
        dkube.garbagecollect: "true"
        dkube.garbagecollect.policy: all
  - name: dkube-training
    container:
      args: [training, --accessurl, --token, '{{inputs.parameters.auth_token}}', --container,
        '{{inputs.parameters.training_container}}', --script, '{{inputs.parameters.training_script}}',
        --program, '{{inputs.parameters.training_program}}', --commit_id, --datasets,
        '["{{inputs.parameters.training_dataset}}"]', --input_dataset_mounts, '["{{inputs.parameters.training_input_dataset_mount}}"]',
        --input_dataset_versions, --models, --input_model_mounts, --input_model_versions,
        --outputs, '["{{inputs.parameters.training_output_model}}"]', --output_mounts,
        '["{{inputs.parameters.training_output_mount}}"]', --ngpus, '{{inputs.parameters.training_gpus}}',
        --nworkers, --auto, --config, --tuning, --envs, '{{inputs.parameters.training_envs}}',
        --gdrdma, --job_group, '{{inputs.parameters.job_group}}', --framework, '{{inputs.parameters.framework}}',
        --version, '{{inputs.parameters.version}}', --runid, '{{pod.name}}', --wfid,
        '{{workflow.uid}}']
      command: [dkubepl]
      image: ocdr/dkubepl:2.1.6.2
    inputs:
      parameters:
      - {name: auth_token}
      - {name: framework}
      - {name: job_group}
      - {name: training_container}
      - {name: training_dataset}
      - {name: training_envs}
      - {name: training_gpus}
      - {name: training_input_dataset_mount}
      - {name: training_output_model}
      - {name: training_output_mount}
      - {name: training_program}
      - {name: training_script}
      - {name: version}
    outputs:
      parameters:
      - name: dkube-training-artifact
        valueFrom: {path: /tmp/artifact}
      artifacts:
      - {name: dkube-training-artifact, path: /tmp/artifact}
      - {name: dkube-training-rundetails, path: /tmp/rundetails}
    metadata:
      annotations: {platform: Dkube, pipelines.kubeflow.org/component_spec: '{"description":
          "Component which can be used to do training for deep learning models on
          Dkube platform.\nDkube training offers,\n* Advanced options for distributed
          training, gpu managment & pooling.\n* Support Hyper parameter tuning.\n*
          GDRDMA support for Horovod like training programs.\n* Ability to orchestrate
          and run custom training containers, prebuilt dkube datascience containers
          can also be used.\n* Renders nice Dashboard for training metrics and utilization
          graphs for GPU, CPU, Memory.\n* Support for early stopping if program is
          not converging - User can abort the Job and resume from previous point in
          training.\n* Tags to group related training jobs.\n", "implementation":
          {"container": {"args": ["training", "--accessurl", {"inputValue": "access_url"},
          "--token", {"inputValue": "auth_token"}, "--container", {"inputValue": "container"},
          "--script", {"inputValue": "run_script"}, "--program", {"inputValue": "program"},
          "--commit_id", {"inputValue": "commit_id"}, "--datasets", {"inputValue":
          "datasets"}, "--input_dataset_mounts", {"inputValue": "input_dataset_mounts"},
          "--input_dataset_versions", {"inputValue": "input_dataset_versions"}, "--models",
          {"inputValue": "models"}, "--input_model_mounts", {"inputValue": "input_model_mounts"},
          "--input_model_versions", {"inputValue": "input_model_versions"}, "--outputs",
          {"inputValue": "outputs"}, "--output_mounts", {"inputValue": "output_mounts"},
          "--ngpus", {"inputValue": "ngpus"}, "--nworkers", {"inputValue": "nworkers"},
          "--auto", {"inputValue": "auto_distribute"}, "--config", {"inputValue":
          "config"}, "--tuning", {"inputValue": "tuning"}, "--envs", {"inputValue":
          "envs"}, "--gdrdma", {"inputValue": "gdrdma"}, "--job_group", {"inputValue":
          "job_group"}, "--framework", {"inputValue": "framework"}, "--version", {"inputValue":
          "version"}, "--runid", "{{pod.name}}", "--wfid", "{{workflow.uid}}"], "command":
          ["dkubepl"], "fileOutputs": {"artifact": "/tmp/artifact", "rundetails":
          "/tmp/rundetails"}, "image": "ocdr/dkubepl:2.1.6.2"}}, "inputs": [{"description":
          "Required. Dkube authentication token.", "name": "auth_token", "type": "String"},
          {"description": "Required. Container to use for training. Format: {\"image\":<url>,
          \"username\":<>, \"password\":<>}", "name": "container", "type": "Dict"},
          {"default": "", "description": "Optional. Program imported in Dkube to be
          run inside container. If not specified container should have entrypoint.",
          "name": "program", "optional": true, "type": "String"}, {"default": "",
          "description": "Optional. Program commit ID. If not provided, dkube takes
          the latest commit.", "name": "commit_id", "optional": true, "type": "String"},
          {"default": "", "description": "Optional. Script to run the program. If
          not specified container should have entrypoint.", "name": "run_script",
          "optional": true, "type": "String"}, {"default": "[]", "description": "Optional.
          List of input datasets required for training. These datasets must be created
          in Dkube.", "name": "datasets", "optional": true, "type": "List"}, {"default":
          "[]", "description": "Optional. List of input datasets mount paths.", "name":
          "input_dataset_mounts", "optional": true, "type": "List"}, {"default": "[]",
          "description": "Optional. List of input datasets versions.", "name": "input_dataset_versions",
          "optional": true, "type": "List"}, {"default": "[]", "description": "Optional.
          List of input models required for training. These models must be created
          in Dkube.", "name": "models", "optional": true, "type": "List"}, {"default":
          "[]", "description": "Optional. List of input models mount paths.", "name":
          "input_model_mounts", "optional": true, "type": "List"}, {"default": "[]",
          "description": "Optional. List of input models mount versions.", "name":
          "input_model_versions", "optional": true, "type": "List"}, {"default": "[]",
          "description": "Required. List of output models of a training", "name":
          "outputs", "optional": true, "type": "List"}, {"default": "[]", "description":
          "Required. List of output model mount paths", "name": "output_mounts", "optional":
          true, "type": "List"}, {"default": 0, "description": "Optional. Number of
          gpus the training program should use.", "name": "ngpus", "optional": true,
          "type": "Integer"}, {"default": 0, "description": "Optional. Number of workers
          for training, >0 for distributed training.", "name": "nworkers", "optional":
          true, "type": "Integer"}, {"default": "false", "description": "Optional.
          Should Dkube auto distribute based on available number of resources.", "name":
          "auto_distribute", "optional": true, "type": "String"}, {"default": "",
          "description": "Optional. HP file or configuration data required for training
          program. Supported inputs - d3s://<path> - Path to a file in dkube storage.
          <string> - Inline data", "name": "config", "optional": true, "type": "String"},
          {"default": "", "description": "Optional. HP tuning information. Can be
          a URL to a file with hptuning definition or inline data. Supported inputs
          - d3s://<path> - Path to a file in dkube storage. <string> - Inline data,
          only json formatted string is valid.", "name": "tuning", "optional": true,
          "type": "String"}, {"default": "[]", "description": "Optional. Environments
          for training program. Exact key value will be made available for the container",
          "name": "envs", "optional": true, "type": "List"}, {"default": "false",
          "description": "Optional. Whether to use GDRDMA for distributed training.",
          "name": "gdrdma", "optional": true, "type": "String"}, {"default": "", "description":
          "Optional. URL at which dkube is accessible, copy paste from the browser
          of this window. Required for cloud deployments.", "name": "access_url",
          "optional": true, "type": "String"}, {"default": "default", "description":
          "Optional. Runs can be organized into Groups that allow them to be viewed
          together. This group must be created in Dkube.", "name": "job_group", "optional":
          true, "type": "String"}, {"description": "Required. Framework {tensorflow,
          pytorch, sklearn, custom...}.", "name": "framework", "type": "String"},
          {"description": "Required. Framework version.", "name": "version", "type":
          "String"}], "metadata": {"annotations": {"platform": "Dkube"}, "labels":
          {"dkube.garbagecollect": "true", "dkube.garbagecollect.policy": "all", "logger":
          "dkubepl", "platform": "Dkube", "runid": "{{pod.name}}", "stage": "training",
          "wfid": "{{workflow.uid}}"}}, "name": "dkube-training", "outputs": [{"description":
          "Details of the dkube run", "name": "rundetails"}, {"description": "Identifier
          in Dkube storage where artifacts of training are stored.", "name": "artifact"}]}',
        pipelines.kubeflow.org/component_ref: '{"digest": "ca3eb2219c2505e4d982d8e18291cf874d562582bfb4afb77716ea5b71d0fc7c",
          "url": "../components/training/component.yaml"}'}
      labels:
        platform: Dkube
        logger: dkubepl
        wfid: '{{workflow.uid}}'
        runid: '{{pod.name}}'
        stage: training
        dkube.garbagecollect: "true"
        dkube.garbagecollect.policy: all
  arguments:
    parameters:
    - {name: auth_token}
    - {name: training_program}
    - {name: training_dataset}
    - {name: training_output_model}
    - {name: job_group, value: default}
    - {name: framework, value: tensorflow}
    - {name: version, value: '1.14'}
    - {name: training_container, value: '{"image": "docker.io/ocdr/d3-datascience-tf-cpu:v1.14",
        "username": "", "password": ""}'}
    - {name: training_script, value: python model.py}
    - {name: training_input_dataset_mount, value: /opt/dkube/input}
    - {name: training_output_mount, value: /opt/dkube/output}
    - {name: training_gpus, value: '0'}
    - {name: training_envs, value: '[{"steps": 100}]'}
    - {name: serving_image, value: '{"image": "ocdr/tensorflowserver:1.14", "username":
        "", "password": ""}'}
    - {name: transformer_image, value: '{"image": "docker.io/ocdr/d3-datascience-tf-cpu:v1.14",
        "username": "", "password": ""}'}
    - {name: transformer_code, value: tensorflow/classification/resnet/catsdogs/transformer/transformer.py}
  serviceAccountName: pipeline-runner
