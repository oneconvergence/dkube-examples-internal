apiVersion: argoproj.io/v1alpha1
kind: Workflow
metadata:
  generateName: mnist-
  annotations: {pipelines.kubeflow.org/kfp_sdk_version: 1.0.0, pipelines.kubeflow.org/pipeline_compilation_time: '2020-12-04T07:46:57.471255',
    pipelines.kubeflow.org/pipeline_spec: '{"description": "sample mnist digits pipeline
      with dkube components", "inputs": [{"name": "auth_token"}, {"name": "training_program"},
      {"name": "preprocessing_dataset"}, {"name": "training_featureset"}, {"name":
      "training_output_model"}, {"default": "python featureset.py", "name": "data_preprocess_script",
      "optional": true}, {"default": "/opt/dkube/input", "name": "data_preprocess_input_mounts",
      "optional": true}, {"default": "/opt/dkube/output", "name": "data_preprocess_output_mounts",
      "optional": true}, {"default": "default", "name": "job_group", "optional": true},
      {"default": "tensorflow", "name": "framework", "optional": true}, {"default":
      "1.14", "name": "version", "optional": true}, {"default": "{\"image\": \"docker.io/ocdr/d3-datascience-tf-cpu:fs-v1.14\",
      \"username\": \"\", \"password\": \"\"}", "name": "training_container", "optional":
      true}, {"default": "python model.py", "name": "training_script", "optional":
      true}, {"default": "/opt/dkube/input", "name": "training_input_featureset_mount",
      "optional": true}, {"default": "/opt/dkube/output", "name": "training_output_mount",
      "optional": true}, {"default": "0", "name": "training_gpus", "optional": true},
      {"default": "[{\"steps\": 100}]", "name": "training_envs", "optional": true},
      {"default": "{}", "name": "tuning", "optional": true}, {"default": "cpu", "name":
      "serving_device", "optional": true}, {"default": "{\"image\": \"ocdr/tensorflowserver:1.14\",
      \"username\": \"\", \"password\": \"\"}", "name": "serving_image", "optional":
      true}, {"default": "{\"image\": \"docker.io/ocdr/d3-datascience-tf-cpu:v1.14\",
      \"username\": \"\", \"password\": \"\"}", "name": "transformer_image", "optional":
      true}, {"default": "tf/classification/mnist-fs/digits/transformer/transformer.py",
      "name": "transformer_code", "optional": true}], "name": "mnist"}'}
  labels: {pipelines.kubeflow.org/kfp_sdk_version: 1.0.0}
spec:
  entrypoint: mnist
  templates:
  - name: dkube-preprocess
    container:
      args: [preprocess, --accessurl, --token, '{{inputs.parameters.auth_token}}',
        --container, '{{inputs.parameters.training_container}}', --script, '{{inputs.parameters.data_preprocess_script}}',
        --program, '{{inputs.parameters.training_program}}', --commit_id, --datasets,
        '["{{inputs.parameters.preprocessing_dataset}}"]', --input_dataset_mounts,
        '["{{inputs.parameters.data_preprocess_input_mounts}}"]', --input_dataset_versions,
        --input_featuresets, --input_featureset_mounts, --input_featureset_versions,
        --models, --input_model_mounts, --input_model_versions, --outputs, --output_mounts,
        --output_featuresets, '["{{inputs.parameters.training_featureset}}"]', --output_featureset_mounts,
        '["{{inputs.parameters.data_preprocess_output_mounts}}"]', --ngpus, --config,
        --envs, --job_group, --tags, --runid, '{{pod.name}}', --wfid, '{{workflow.uid}}']
      command: [dkubepl]
      image: ocdr/dkubepl:2.2.1.2
    inputs:
      parameters:
      - {name: auth_token}
      - {name: data_preprocess_input_mounts}
      - {name: data_preprocess_output_mounts}
      - {name: data_preprocess_script}
      - {name: preprocessing_dataset}
      - {name: training_container}
      - {name: training_featureset}
      - {name: training_program}
    outputs:
      artifacts:
      - {name: dkube-preprocess-artifact, path: /tmp/artifact}
      - {name: dkube-preprocess-rundetails, path: /tmp/rundetails}
    metadata:
      annotations: {platform: Dkube, pipelines.kubeflow.org/component_spec: '{"description":
          "Component which can be used to perform data preprocessing on Dkube platform.\nDkube
          preprocess provides,\n* Ability to orchestrate and run custom containers.\n*
          Renders utilization graphs for CPU, Memory.\n* Tags to group related preprocessing
          jobs.\n", "implementation": {"container": {"args": ["preprocess", "--accessurl",
          {"inputValue": "access_url"}, "--token", {"inputValue": "auth_token"}, "--container",
          {"inputValue": "container"}, "--script", {"inputValue": "run_script"}, "--program",
          {"inputValue": "program"}, "--commit_id", {"inputValue": "commit_id"}, "--datasets",
          {"inputValue": "datasets"}, "--input_dataset_mounts", {"inputValue": "input_dataset_mounts"},
          "--input_dataset_versions", {"inputValue": "input_dataset_versions"}, "--input_featuresets",
          {"inputValue": "input_featuresets"}, "--input_featureset_mounts", {"inputValue":
          "input_featureset_mounts"}, "--input_featureset_versions", {"inputValue":
          "input_featureset_versions"}, "--models", {"inputValue": "models"}, "--input_model_mounts",
          {"inputValue": "input_model_mounts"}, "--input_model_versions", {"inputValue":
          "input_model_versions"}, "--outputs", {"inputValue": "outputs"}, "--output_mounts",
          {"inputValue": "output_mounts"}, "--output_featuresets", {"inputValue":
          "output_featuresets"}, "--output_featureset_mounts", {"inputValue": "output_featureset_mounts"},
          "--ngpus", {"inputValue": "ngpus"}, "--config", {"inputValue": "config"},
          "--envs", {"inputValue": "envs"}, "--job_group", {"inputValue": "job_group"},
          "--tags", {"inputValue": "tags"}, "--runid", "{{pod.name}}", "--wfid", "{{workflow.uid}}"],
          "command": ["dkubepl"], "fileOutputs": {"artifact": "/tmp/artifact", "rundetails":
          "/tmp/rundetails"}, "image": "ocdr/dkubepl:2.2.1.2"}}, "inputs": [{"description":
          "Required. Dkube authentication token.", "name": "auth_token", "type": "String"},
          {"description": "Required. Container to use for preprocessing. Format: {\"image\":<url>,
          \"username\":<>, \"password\":<>}", "name": "container", "type": "Dict"},
          {"default": "", "description": "Optional. Program imported in Dkube to be
          run inside container. If not specified container should have entrypoint.",
          "name": "program", "optional": true, "type": "String"}, {"default": "",
          "description": "Optional. Program commit ID. If not provided, dkube takes
          the latest commit.", "name": "commit_id", "optional": true, "type": "String"},
          {"default": "", "description": "Optional. Script to run the program. If
          not specified container should have entrypoint.", "name": "run_script",
          "optional": true, "type": "String"}, {"default": "[]", "description": "Optional.
          List of input datasets required for preprocessing. These datasets must be
          created in Dkube.", "name": "datasets", "optional": true, "type": "List"},
          {"default": "[]", "description": "Optional. List of input datasets mount
          paths.", "name": "input_dataset_mounts", "optional": true, "type": "List"},
          {"default": "[]", "description": "Optional. List of input datasets versions.",
          "name": "input_dataset_versions", "optional": true, "type": "List"}, {"default":
          "[]", "description": "Optional. List of input featuresets required for preprocessing.
          These featuresets must be created in Dkube.", "name": "input_featuresets",
          "optional": true, "type": "List"}, {"default": "[]", "description": "Optional.
          List of input featuresets mount paths.", "name": "input_featureset_mounts",
          "optional": true, "type": "List"}, {"default": "[]", "description": "Optional.
          List of input featureset versions.", "name": "input_featureset_versions",
          "optional": true, "type": "List"}, {"default": "[]", "description": "Optional.
          List of input models required for preprocessing. These models must be created
          in Dkube.", "name": "models", "optional": true, "type": "List"}, {"default":
          "[]", "description": "Optional. List of input models mount paths.", "name":
          "input_model_mounts", "optional": true, "type": "List"}, {"default": "[]",
          "description": "Optional. List of input models versions.", "name": "input_model_versions",
          "optional": true, "type": "List"}, {"description": "Required. List of output
          datasets of a datajob", "name": "outputs", "optional": true, "type": "List"},
          {"description": "Required. List of output datasets mount paths", "name":
          "output_mounts", "optional": true, "type": "List"}, {"description": "Required.
          List of output featuresets of a datajob", "name": "output_featuresets",
          "optional": true, "type": "List"}, {"description": "Required. List of output
          featuresets mount paths", "name": "output_featureset_mounts", "optional":
          true, "type": "List"}, {"default": 0, "description": "Optional. Number of
          gpus the training program should use.", "name": "ngpus", "optional": true,
          "type": "Integer"}, {"default": "", "description": "Optional. HP file or
          configuration data required for training program. Supported inputs - d3s://<path>
          - Path to a file in dkube storage. <string> - Inline data", "name": "config",
          "optional": true, "type": "String"}, {"default": "[]", "description": "Optional.
          Environments for preprocess program. Exact key value will be made available
          for the container", "name": "envs", "optional": true, "type": "List"}, {"default":
          "", "description": "Optional. URL at which dkube is accessible, copy paste
          from the browser of this window. Required for cloud deployments.", "name":
          "access_url", "optional": true, "type": "String"}, {"default": "default",
          "description": "Optional. Runs can be organized into Groups that allow them
          to be viewed together. This group must be created in Dkube.", "name": "job_group",
          "optional": true, "type": "String"}, {"default": "[]", "description": "Optional.
          List of user-chosen tags to allow Runs to be better identified or grouped.",
          "name": "tags", "optional": true, "type": "List"}], "metadata": {"annotations":
          {"platform": "Dkube"}, "labels": {"dkube.garbagecollect": "true", "dkube.garbagecollect.policy":
          "all", "logger": "dkubepl", "platform": "Dkube", "runid": "{{pod.name}}",
          "stage": "preprocess", "wfid": "{{workflow.uid}}"}}, "name": "dkube-preprocess",
          "outputs": [{"description": "Details of the dkube run", "name": "rundetails"},
          {"description": "Identifier in Dkube storage where artifact generated by
          this component are stored.", "name": "artifact"}]}', pipelines.kubeflow.org/component_ref: '{"digest":
          "0f042daff6810ebba25adab1e5971c97c327544c69c2ac6b46e5da5e11cca57a", "url":
          "../components/preprocess/component.yaml"}'}
      labels:
        platform: Dkube
        logger: dkubepl
        wfid: '{{workflow.uid}}'
        runid: '{{pod.name}}'
        stage: preprocess
        dkube.garbagecollect: "true"
        dkube.garbagecollect.policy: all
  - name: dkube-serving
    container:
      args: [serving, --accessurl, --token, '{{inputs.parameters.auth_token}}', --model,
        '{{inputs.parameters.dkube-training-artifact}}', --model_version, --device,
        '{{inputs.parameters.serving_device}}', --serving_image, '{{inputs.parameters.serving_image}}',
        --transformer_image, '{{inputs.parameters.transformer_image}}', --transformer_project,
        '{{inputs.parameters.training_program}}', --transformer_code, '{{inputs.parameters.transformer_code}}',
        --transformer_commit_id, --runid, '{{pod.name}}', --wfid, '{{workflow.uid}}']
      command: [dkubepl]
      image: ocdr/dkubepl:2.2.1.2
    inputs:
      parameters:
      - {name: auth_token}
      - {name: dkube-training-artifact}
      - {name: serving_device}
      - {name: serving_image}
      - {name: training_program}
      - {name: transformer_code}
      - {name: transformer_image}
    outputs:
      artifacts:
      - {name: dkube-serving-rundetails, path: /tmp/rundetails}
      - {name: dkube-serving-servingurl, path: /tmp/servingurl}
    metadata:
      annotations: {platform: Dkube, pipelines.kubeflow.org/component_spec: '{"description":
          "Component which can be used to deploy a trained model on Dkube platform.\nDkube
          serving provides,\n* Option to deploy with CPU/GPU.\n* A web server in the
          front and all the required infra to access the server.\n* Deployed as microserice.
          Serving URL is provided for any other application logic to consume the model.\n*
          Attempts to decode and present some abstract information about the model.\n",
          "implementation": {"container": {"args": ["serving", "--accessurl", {"inputValue":
          "access_url"}, "--token", {"inputValue": "auth_token"}, "--model", {"inputValue":
          "model"}, "--model_version", {"inputValue": "model_version"}, "--device",
          {"inputValue": "device"}, "--serving_image", {"inputValue": "serving_image"},
          "--transformer_image", {"inputValue": "transformer_image"}, "--transformer_project",
          {"inputValue": "transformer_project"}, "--transformer_code", {"inputValue":
          "transformer_code"}, "--transformer_commit_id", {"inputValue": "transformer_commit_id"},
          "--runid", "{{pod.name}}", "--wfid", "{{workflow.uid}}"], "command": ["dkubepl"],
          "fileOutputs": {"rundetails": "/tmp/rundetails", "servingurl": "/tmp/servingurl"},
          "image": "ocdr/dkubepl:2.2.1.2"}}, "inputs": [{"description": "Required.
          Dkube authentication token.", "name": "auth_token", "type": "String"}, {"description":
          "Required. Trained model in Dkube which is to be deployed for serving.",
          "name": "model", "type": "String"}, {"description": "Optional. Trained model
          version.", "name": "model_version", "optional": true, "type": "String"},
          {"default": "cpu", "description": "Optional. Device to use for serving -
          allowed values, gpu/cpu/auto.", "name": "device", "optional": true, "type":
          "String"}, {"default": "", "description": "Optional. URL at which dkube
          is accessible, copy paste from the browser of this window. Required for
          cloud deployments.", "name": "access_url", "optional": true, "type": "String"},
          {"description": "Required. Container to use for serving. Format: {\"image\":<url>,
          \"username\":<>, \"password\":<>}", "name": "serving_image", "type": "Dict"},
          {"description": "Required. Container to use as transformer. Format: {\"image\":<url>,
          \"username\":<>, \"password\":<>}", "name": "transformer_image", "optional":
          true, "type": "Dict"}, {"description": "Required. Transformer project.",
          "name": "transformer_project", "optional": true, "type": "String"}, {"description":
          "Required. Transformer script.", "name": "transformer_code", "optional":
          true, "type": "String"}, {"description": "Optional. Transformer project
          commit ID.", "name": "transformer_commit_id", "optional": true, "type":
          "String"}], "metadata": {"annotations": {"platform": "Dkube"}, "labels":
          {"dkube.garbagecollect": "true", "dkube.garbagecollect.policy": "all", "logger":
          "dkubepl", "platform": "Dkube", "runid": "{{pod.name}}", "stage": "serving",
          "wfid": "{{workflow.uid}}"}}, "name": "dkube-serving", "outputs": [{"description":
          "Details of the dkube run", "name": "rundetails"}, {"description": "URL
          at which the serving web server is accessible.", "name": "servingurl"}]}',
        pipelines.kubeflow.org/component_ref: '{"digest": "d76c6497fa3858b719b4b6767858e0854f35b9803cec9c2a2b380fa036ca014b",
          "url": "../components/serving/component.yaml"}'}
      labels:
        platform: Dkube
        logger: dkubepl
        wfid: '{{workflow.uid}}'
        runid: '{{pod.name}}'
        stage: serving
        dkube.garbagecollect: "true"
        dkube.garbagecollect.policy: all
  - name: dkube-training
    container:
      args: [training, --accessurl, --token, '{{inputs.parameters.auth_token}}', --container,
        '{{inputs.parameters.training_container}}', --script, '{{inputs.parameters.training_script}}',
        --program, '{{inputs.parameters.training_program}}', --commit_id, --datasets,
        --input_dataset_mounts, --input_dataset_versions, --input_featuresets, '["{{inputs.parameters.training_featureset}}"]',
        --input_featureset_mounts, '["{{inputs.parameters.training_input_featureset_mount}}"]',
        --input_featureset_versions, --models, --input_model_mounts, --input_model_versions,
        --outputs, '["{{inputs.parameters.training_output_model}}"]', --output_mounts,
        '["{{inputs.parameters.training_output_mount}}"]', --ngpus, '{{inputs.parameters.training_gpus}}',
        --nworkers, --auto, --config, --tuning, '{{inputs.parameters.tuning}}', --envs,
        '{{inputs.parameters.training_envs}}', --gdrdma, --job_group, '{{inputs.parameters.job_group}}',
        --framework, '{{inputs.parameters.framework}}', --version, '{{inputs.parameters.version}}',
        --tags, --runid, '{{pod.name}}', --wfid, '{{workflow.uid}}']
      command: [dkubepl]
      image: ocdr/dkubepl:2.2.1.2
    inputs:
      parameters:
      - {name: auth_token}
      - {name: framework}
      - {name: job_group}
      - {name: training_container}
      - {name: training_envs}
      - {name: training_featureset}
      - {name: training_gpus}
      - {name: training_input_featureset_mount}
      - {name: training_output_model}
      - {name: training_output_mount}
      - {name: training_program}
      - {name: training_script}
      - {name: tuning}
      - {name: version}
    outputs:
      parameters:
      - name: dkube-training-artifact
        valueFrom: {path: /tmp/artifact}
      artifacts:
      - {name: dkube-training-artifact, path: /tmp/artifact}
      - {name: dkube-training-rundetails, path: /tmp/rundetails}
    metadata:
      annotations: {platform: Dkube, pipelines.kubeflow.org/component_spec: '{"description":
          "Component which can be used to do training for deep learning models on
          Dkube platform.\nDkube training offers,\n* Advanced options for distributed
          training, gpu managment & pooling.\n* Support Hyper parameter tuning.\n*
          GDRDMA support for Horovod like training programs.\n* Ability to orchestrate
          and run custom training containers, prebuilt dkube datascience containers
          can also be used.\n* Renders nice Dashboard for training metrics and utilization
          graphs for GPU, CPU, Memory.\n* Support for early stopping if program is
          not converging - User can abort the Job and resume from previous point in
          training.\n* Tags to group related training jobs.\n", "implementation":
          {"container": {"args": ["training", "--accessurl", {"inputValue": "access_url"},
          "--token", {"inputValue": "auth_token"}, "--container", {"inputValue": "container"},
          "--script", {"inputValue": "run_script"}, "--program", {"inputValue": "program"},
          "--commit_id", {"inputValue": "commit_id"}, "--datasets", {"inputValue":
          "datasets"}, "--input_dataset_mounts", {"inputValue": "input_dataset_mounts"},
          "--input_dataset_versions", {"inputValue": "input_dataset_versions"}, "--input_featuresets",
          {"inputValue": "featuresets"}, "--input_featureset_mounts", {"inputValue":
          "input_featureset_mounts"}, "--input_featureset_versions", {"inputValue":
          "input_featureset_versions"}, "--models", {"inputValue": "models"}, "--input_model_mounts",
          {"inputValue": "input_model_mounts"}, "--input_model_versions", {"inputValue":
          "input_model_versions"}, "--outputs", {"inputValue": "outputs"}, "--output_mounts",
          {"inputValue": "output_mounts"}, "--ngpus", {"inputValue": "ngpus"}, "--nworkers",
          {"inputValue": "nworkers"}, "--auto", {"inputValue": "auto_distribute"},
          "--config", {"inputValue": "config"}, "--tuning", {"inputValue": "tuning"},
          "--envs", {"inputValue": "envs"}, "--gdrdma", {"inputValue": "gdrdma"},
          "--job_group", {"inputValue": "job_group"}, "--framework", {"inputValue":
          "framework"}, "--version", {"inputValue": "version"}, "--tags", {"inputValue":
          "tags"}, "--runid", "{{pod.name}}", "--wfid", "{{workflow.uid}}"], "command":
          ["dkubepl"], "fileOutputs": {"artifact": "/tmp/artifact", "rundetails":
          "/tmp/rundetails"}, "image": "ocdr/dkubepl:2.2.1.2"}}, "inputs": [{"description":
          "Required. Dkube authentication token.", "name": "auth_token", "type": "String"},
          {"description": "Required. Container to use for training. Format: {\"image\":<url>,
          \"username\":<>, \"password\":<>}", "name": "container", "type": "Dict"},
          {"default": "", "description": "Optional. Program imported in Dkube to be
          run inside container. If not specified container should have entrypoint.",
          "name": "program", "optional": true, "type": "String"}, {"default": "",
          "description": "Optional. Program commit ID. If not provided, dkube takes
          the latest commit.", "name": "commit_id", "optional": true, "type": "String"},
          {"default": "", "description": "Optional. Script to run the program. If
          not specified container should have entrypoint.", "name": "run_script",
          "optional": true, "type": "String"}, {"default": "[]", "description": "Optional.
          List of input datasets required for training. These datasets must be created
          in Dkube.", "name": "datasets", "optional": true, "type": "List"}, {"default":
          "[]", "description": "Optional. List of input datasets mount paths.", "name":
          "input_dataset_mounts", "optional": true, "type": "List"}, {"default": "[]",
          "description": "Optional. List of input datasets versions.", "name": "input_dataset_versions",
          "optional": true, "type": "List"}, {"default": "[]", "description": "Optional.
          List of input featuresets required for training. These featuresets must
          be created in Dkube.", "name": "featuresets", "optional": true, "type":
          "List"}, {"default": "[]", "description": "Optional. List of input featureset
          mount paths.", "name": "input_featureset_mounts", "optional": true, "type":
          "List"}, {"default": "[]", "description": "Optional. List of input featureset
          versions.", "name": "input_featureset_versions", "optional": true, "type":
          "List"}, {"default": "[]", "description": "Optional. List of input models
          required for training. These models must be created in Dkube.", "name":
          "models", "optional": true, "type": "List"}, {"default": "[]", "description":
          "Optional. List of input models mount paths.", "name": "input_model_mounts",
          "optional": true, "type": "List"}, {"default": "[]", "description": "Optional.
          List of input models mount versions.", "name": "input_model_versions", "optional":
          true, "type": "List"}, {"default": "[]", "description": "Required. List
          of output models of a training", "name": "outputs", "optional": true, "type":
          "List"}, {"default": "[]", "description": "Required. List of output model
          mount paths", "name": "output_mounts", "optional": true, "type": "List"},
          {"default": 0, "description": "Optional. Number of gpus the training program
          should use.", "name": "ngpus", "optional": true, "type": "Integer"}, {"default":
          0, "description": "Optional. Number of workers for training, >0 for distributed
          training.", "name": "nworkers", "optional": true, "type": "Integer"}, {"default":
          "false", "description": "Optional. Should Dkube auto distribute based on
          available number of resources.", "name": "auto_distribute", "optional":
          true, "type": "String"}, {"default": "", "description": "Optional. HP file
          or configuration data required for training program. Supported inputs -
          d3s://<path> - Path to a file in dkube storage. <string> - Inline data",
          "name": "config", "optional": true, "type": "String"}, {"default": "", "description":
          "Optional. HP tuning information. Can be a URL to a file with hptuning definition
          or inline data. Supported inputs - d3s://<path> - Path to a file in dkube
          storage. <string> - Inline data, only json formatted string is valid.",
          "name": "tuning", "optional": true, "type": "String"}, {"default": "[]",
          "description": "Optional. Environments for training program. Exact key value
          will be made available for the container", "name": "envs", "optional": true,
          "type": "List"}, {"default": "false", "description": "Optional. Whether
          to use GDRDMA for distributed training.", "name": "gdrdma", "optional":
          true, "type": "String"}, {"default": "", "description": "Optional. URL at
          which dkube is accessible, copy paste from the browser of this window. Required
          for cloud deployments.", "name": "access_url", "optional": true, "type":
          "String"}, {"default": "default", "description": "Optional. Runs can be
          organized into Groups that allow them to be viewed together. This group
          must be created in Dkube.", "name": "job_group", "optional": true, "type":
          "String"}, {"description": "Required. Framework {tensorflow, pytorch, sklearn,
          custom...}.", "name": "framework", "type": "String"}, {"description": "Required.
          Framework version.", "name": "version", "type": "String"}, {"default": "[]",
          "description": "Optional. List of user-chosen tags to allow Runs to be better
          identified or grouped.", "name": "tags", "optional": true, "type": "List"}],
          "metadata": {"annotations": {"platform": "Dkube"}, "labels": {"dkube.garbagecollect":
          "true", "dkube.garbagecollect.policy": "all", "logger": "dkubepl", "platform":
          "Dkube", "runid": "{{pod.name}}", "stage": "training", "wfid": "{{workflow.uid}}"}},
          "name": "dkube-training", "outputs": [{"description": "Details of the dkube
          run", "name": "rundetails"}, {"description": "Identifier in Dkube storage
          where artifacts of training are stored.", "name": "artifact"}]}', pipelines.kubeflow.org/component_ref: '{"digest":
          "07b91d409da07cdd68e2551fa61f92ed968bdb5ca832d9cb8186b74328205203", "url":
          "../components/training/component.yaml"}'}
      labels:
        platform: Dkube
        logger: dkubepl
        wfid: '{{workflow.uid}}'
        runid: '{{pod.name}}'
        stage: training
        dkube.garbagecollect: "true"
        dkube.garbagecollect.policy: all
  - name: mnist
    inputs:
      parameters:
      - {name: auth_token}
      - {name: data_preprocess_input_mounts}
      - {name: data_preprocess_output_mounts}
      - {name: data_preprocess_script}
      - {name: framework}
      - {name: job_group}
      - {name: preprocessing_dataset}
      - {name: serving_device}
      - {name: serving_image}
      - {name: training_container}
      - {name: training_envs}
      - {name: training_featureset}
      - {name: training_gpus}
      - {name: training_input_featureset_mount}
      - {name: training_output_model}
      - {name: training_output_mount}
      - {name: training_program}
      - {name: training_script}
      - {name: transformer_code}
      - {name: transformer_image}
      - {name: tuning}
      - {name: version}
    dag:
      tasks:
      - name: dkube-preprocess
        template: dkube-preprocess
        arguments:
          parameters:
          - {name: auth_token, value: '{{inputs.parameters.auth_token}}'}
          - {name: data_preprocess_input_mounts, value: '{{inputs.parameters.data_preprocess_input_mounts}}'}
          - {name: data_preprocess_output_mounts, value: '{{inputs.parameters.data_preprocess_output_mounts}}'}
          - {name: data_preprocess_script, value: '{{inputs.parameters.data_preprocess_script}}'}
          - {name: preprocessing_dataset, value: '{{inputs.parameters.preprocessing_dataset}}'}
          - {name: training_container, value: '{{inputs.parameters.training_container}}'}
          - {name: training_featureset, value: '{{inputs.parameters.training_featureset}}'}
          - {name: training_program, value: '{{inputs.parameters.training_program}}'}
      - name: dkube-serving
        template: dkube-serving
        dependencies: [dkube-training]
        arguments:
          parameters:
          - {name: auth_token, value: '{{inputs.parameters.auth_token}}'}
          - {name: dkube-training-artifact, value: '{{tasks.dkube-training.outputs.parameters.dkube-training-artifact}}'}
          - {name: serving_device, value: '{{inputs.parameters.serving_device}}'}
          - {name: serving_image, value: '{{inputs.parameters.serving_image}}'}
          - {name: training_program, value: '{{inputs.parameters.training_program}}'}
          - {name: transformer_code, value: '{{inputs.parameters.transformer_code}}'}
          - {name: transformer_image, value: '{{inputs.parameters.transformer_image}}'}
      - name: dkube-training
        template: dkube-training
        dependencies: [dkube-preprocess]
        arguments:
          parameters:
          - {name: auth_token, value: '{{inputs.parameters.auth_token}}'}
          - {name: framework, value: '{{inputs.parameters.framework}}'}
          - {name: job_group, value: '{{inputs.parameters.job_group}}'}
          - {name: training_container, value: '{{inputs.parameters.training_container}}'}
          - {name: training_envs, value: '{{inputs.parameters.training_envs}}'}
          - {name: training_featureset, value: '{{inputs.parameters.training_featureset}}'}
          - {name: training_gpus, value: '{{inputs.parameters.training_gpus}}'}
          - {name: training_input_featureset_mount, value: '{{inputs.parameters.training_input_featureset_mount}}'}
          - {name: training_output_model, value: '{{inputs.parameters.training_output_model}}'}
          - {name: training_output_mount, value: '{{inputs.parameters.training_output_mount}}'}
          - {name: training_program, value: '{{inputs.parameters.training_program}}'}
          - {name: training_script, value: '{{inputs.parameters.training_script}}'}
          - {name: tuning, value: '{{inputs.parameters.tuning}}'}
          - {name: version, value: '{{inputs.parameters.version}}'}
  arguments:
    parameters:
    - {name: auth_token}
    - {name: training_program}
    - {name: preprocessing_dataset}
    - {name: training_featureset}
    - {name: training_output_model}
    - {name: data_preprocess_script, value: python featureset.py}
    - {name: data_preprocess_input_mounts, value: /opt/dkube/input}
    - {name: data_preprocess_output_mounts, value: /opt/dkube/output}
    - {name: job_group, value: default}
    - {name: framework, value: tensorflow}
    - {name: version, value: '1.14'}
    - {name: training_container, value: '{"image": "docker.io/ocdr/d3-datascience-tf-cpu:fs-v1.14",
        "username": "", "password": ""}'}
    - {name: training_script, value: python model.py}
    - {name: training_input_featureset_mount, value: /opt/dkube/input}
    - {name: training_output_mount, value: /opt/dkube/output}
    - {name: training_gpus, value: '0'}
    - {name: training_envs, value: '[{"steps": 100}]'}
    - {name: tuning, value: '{}'}
    - {name: serving_device, value: cpu}
    - {name: serving_image, value: '{"image": "ocdr/tensorflowserver:1.14", "username":
        "", "password": ""}'}
    - {name: transformer_image, value: '{"image": "docker.io/ocdr/d3-datascience-tf-cpu:v1.14",
        "username": "", "password": ""}'}
    - {name: transformer_code, value: tf/classification/mnist-fs/digits/transformer/transformer.py}
  serviceAccountName: pipeline-runner
